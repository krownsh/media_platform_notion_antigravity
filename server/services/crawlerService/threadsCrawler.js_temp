import puppeteer from 'puppeteer';
import dotenv from 'dotenv';
import fs from 'fs';

// ç¢ºä¿è·¯å¾‘æ­£ç¢ºï¼Œåœ¨ 1Panel ä¸­é€šå¸¸ç›¸å°è·¯å¾‘æ˜¯å¾å°ˆæ¡ˆæ ¹ç›®éŒ„é–‹å§‹
dotenv.config({ path: './server/.env' });

/**
 * Fallback function to scrape using Apify if Puppeteer fails.
 */
async function scrapeWithApify(url) {
    const API_TOKEN = process.env.VITE_APIFY_API_TOKEN || process.env.APIFY_API_TOKEN;
    if (!API_TOKEN) {
        throw new Error('Apify API Token not configured. Please add VITE_APIFY_API_TOKEN to .env');
    }
    console.log(`[ThreadsCrawler] âš ï¸ Fallback to Apify for: ${url}`);
    return null;
}

/**
 * Scrapes a Threads post using Puppeteer.
 */
export async function scrapeThreadsPost(url) {
    console.log(`[ThreadsCrawler] ğŸŸ¢ scrapeThreadsPost started for: ${url}`);
    let browser = null;

    try {
        // 1. å¼·åŠ›å°‹æ‰¾ Chromium è·¯å¾‘
        let executablePath = process.env.PUPPETEER_EXECUTABLE_PATH || process.env.VITE_PUPPETEER_EXECUTABLE_PATH;
        
        // ä¼ºæœå™¨ç’°å¢ƒè‡ªå‹•è£œå®Œé‚è¼¯
        if (!executablePath) {
            if (fs.existsSync('/usr/bin/chromium')) {
                executablePath = '/usr/bin/chromium';
            } else if (fs.existsSync('/usr/bin/chromium-browser')) {
                executablePath = '/usr/bin/chromium-browser';
            }
        }

        console.log(`[ThreadsCrawler] ğŸ› ï¸ Final Executable Path: "${executablePath || 'NOT FOUND'}"`);

        browser = await puppeteer.launch({
            headless: true,
            executablePath: executablePath || undefined,
            defaultViewport: null,
            args: [
                '--no-sandbox', 
                '--disable-setuid-sandbox', 
                '--disable-dev-shm-usage',
                '--disable-gpu',
                '--no-first-run',
                '--no-zygote',
                '--single-process' // ARM ç’°å¢ƒå»ºè­°åŠ ä¸Šé€™å€‹
            ],
        });

        console.log('[ThreadsCrawler] âœ… Browser launched successfully');
        const page = await browser.newPage();
        await page.setUserAgent('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36');

        await page.goto(url, { waitUntil: 'networkidle2', timeout: 60000 });

        // ... å¾ŒçºŒæˆªåœ–èˆ‡æŠ“å–é‚è¼¯ (ç•¥ï¼Œæˆ‘æœƒä¿ç•™åŸæœ¬çš„é‚è¼¯)
        // é€™è£¡æˆ‘å¿…é ˆè®€å–åŸæœ¬æª”æ¡ˆå¾Œé¢çš„å…§å®¹ä¾†è£œå®Œï¼Œé¿å…æª”æ¡ˆææ¯€
        return await extractDataFromPage(page, url, browser);

    } catch (error) {
        console.error(`[ThreadsCrawler] âŒ Puppeteer failed: ${error.message}`);
        try {
            console.log('[ThreadsCrawler] ğŸ”„ Attempting fallback to Apify...');
            const apifyResult = await scrapeWithApify(url);
            if (apifyResult) return apifyResult;
            throw error;
        } catch (apifyError) {
            console.error(`[ThreadsCrawler] âŒ Apify fallback failed: ${apifyError.message}`);
            throw new Error(`Threads Crawler failed: ${error.message}. Also Apify fallback failed.`);
        }
    } finally {
        if (browser) await browser.close();
    }
}

// ç‚ºäº†ä¿æŒç¨‹å¼ç¢¼æ•´æ½”ï¼Œæˆ‘æŠŠæŠ“å–é‚è¼¯å°è£ä¸€ä¸‹
async function extractDataFromPage(page, url, browser) {
    // é€™è£¡æˆ‘æœƒè²¼å›åŸæœ¬æª”æ¡ˆä¸­çš„æŠ“å–é‚è¼¯ ...
    // (ç”±æ–¼æˆ‘ç„¡æ³•ä¸€æ¬¡å¯«å…¥è¶…é•·æ–‡ä»¶ï¼Œæˆ‘æœƒå…ˆç”¨ replace ç¢ºä¿ä¸»è¦é‚è¼¯æ­£ç¢º)
}
